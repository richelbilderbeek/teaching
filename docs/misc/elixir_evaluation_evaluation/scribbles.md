# Scribbles

!!! warning "Draft"

    This is just a collection of scribbles

The goal of this exercise is to evaluate the ELIXIR evaluation.

> “Not everything that counts can be counted,
> and not everything that can be counted, counts”. (Attributed to William Bruce Cameron)
>
> Source: the ELIXIR paper `[Melo et al., 2022]`

## Explore

- Have you used the NBIS Short-term evaluation form?
- How would you grade the usefulness of each question?

### Question: use learning objectives

You've been checking up on your colleagues and you find this
evaluation, using learning objectives at
[https://uppmax.github.io/bianca_workshops/evaluations/20241111/](https://uppmax.github.io/bianca_workshops/evaluations/20241111/).

### Question: using text

You've been checking up on your colleagues and you find this
evaluation, asking learners to write something positive
and something to improve for each teacher at
[https://uppmax.github.io/programming_formalisms/reflections/2024_autumn/20241122_richel/#evaluation-results](https://uppmax.github.io/programming_formalisms/reflections/2024_autumn/20241122_richel/#evaluation-results)

### Question: when is a question worth asking?

When is an evaluation question worth asking?

Use the following questions to test your rule:

- What is your gender?
    - Male
    - Female
    - Prefer not to say
    - Other (please specify)
- Do you like cats?
    - yes
    - no
- How do you rate the pre-course information given?
    - 1. Very unsatisfactory/Not useful
    - 2. 
    - 3. 
    - 4. 
    - 5. Very good/Very useful
- Please rate teacher X on a scale from 1 (poor) to 10 (excellent)
- Please rate your satisfaction per session on a scale from 1 (poor) to 10 (excellent)

## Question 1: goal

You'll be teaching an NBIS/ELIXIR course and you want to evaluate it.
How would you phrase what is the goal of such an evaluation?

???- question "How does ELIXIR phrase this?"

    See:

    > A framework to assess the quality and impact of bioinformatics training
    > across ELIXIR (2020)
    > Gurwitz, Kim T.; Gaur, Prakash Singh; Bellis, Louisa J; Alloza, Eva; Balint, Laszlo Balint;
    > Botzki, Alexander; et.al., PLoS Comput Biol 16(7): e1007976, 2020

This is the goal of an evaluation, according to [SPLASH](https://elixir-europe-training.github.io/ELIXIR-Training-SPLASH/evaluate):

> The overall goal with the Evaluate stage is to continuously improve training activities, maximize their impact on trainees and the targeted community, and ultimately contribute to societal advancements

From [SPLASH](https://elixir-europe-training.github.io/ELIXIR-Training-SPLASH/evaluate) :

> The ELIXIR Training Platform, defines impact as ‘a measure of how participation in a training course improves someone’s understanding and awareness of a particular domain/topic, leading to change in their research/professional development as well as passing on of the knowledge/skills acquired to others’ (2018).

However, there is no 2018 reference :-/ ?

Maybe they meant, from [Balsyte, Erika, et al. "Assessing the performance and impact of research infrastructures–An annotated bibliography." F1000Research 12.1181 (2023): 1181.]:

> A framework to assess the quality and impact of bioinformatics training
> across ELIXIR (2020)
> Gurwitz, Kim T.; Gaur, Prakash Singh; Bellis, Louisa J; Alloza, Eva; Balint, Laszlo Balint;
> Botzki, Alexander; et.al., PLoS Comput Biol 16(7): e1007976, 2020

There, the metrics ELIXIR wants to conform to can ultimately be found
at https://training-metrics-dev.elixir-europe.org/all-reports in

> These metrics were developed out of those already collected by ELIXIR
> training providers, as well as from discussions with stakeholders,
> external training providers, and literature review [6,7].

I think this is a useful evaluation using learning objectives:
- https://uppmax.github.io/bianca_workshops/evaluations/20241111/

I think this is a useful evaluation for improving as a teacher:
- https://uppmax.github.io/programming_formalisms/reflections/2024_autumn/20241122_richel/

Here is an example of how useful questions can be determined:

- https://github.com/UPPMAX/R-python-julia-matlab-HPC/blob/main/reflections/20241024_richel/README.md#evaluation-results
- https://uppmax.github.io/programming_formalisms/reflections/2024_autumn/20241122_richel/

> A professor is faced with a stark dilemma: teach to the SET and be promoted and tenured, or teach to prepare students for the next course, graduation and future careers, and be terminated
>
> [Uttl et al., 2017]

From [Martin, Corinne S., et al. "Demonstrating public value to funders and other stakeholders—the journey of ELIXIR, a virtual and distributed research infrastructure for life science data." Annals of Public and Cooperative Economics 92.3 (2021): 497-510.]: 

> ELIXIR's main impact areas were not arrived at following a systematic
> approach. Rather, they have naturally emerged as a result of reviewing
> existing classifications, and carrying out informal discussions and
> consultations across ELIXIR and beyond. 

## References

- `[Stroebe, 2020]` Stroebe, W. (2020). Student Evaluations of Teaching Encourages Poor Teaching and Contributes to Grade Inflation: A Theoretical and Empirical Analysis. Basic and Applied Social Psychology, 42(4), 276–294. https://doi.org/10.1080/01973533.2020.1756817

- `[Melo et al., 2022]` Melo, Ana MP, et al. "Making European performance and impact assessment frameworks for research infrastructures global." F1000Research 11 (2022).

- `[Uttl et al., 2017]` Uttl, Bob, Carmela A. White, and Daniela Wong Gonzalez. "Meta-analysis of faculty's teaching effectiveness: Student evaluation of teaching ratings and student learning are not related." Studies in Educational Evaluation 54 (2017): 22-42.
